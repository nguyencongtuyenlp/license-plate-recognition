<div align="center">

# ğŸš— License Plate Recognition System

**End-to-End Deep Learning Pipeline for Vehicle Tracking & ALPR**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red?logo=pytorch)](https://pytorch.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100%2B-009688?logo=fastapi)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

**[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Architecture](#-architecture) â€¢ [Training](#-training) â€¢ [API](#-api-server) â€¢ [Skills](#-technical-skills-demonstrated)**

<img src="https://img.shields.io/badge/Built%20with-â¤ï¸%20%26%20PyTorch-red" alt="Built with Love">

---

</div>

## ğŸ“‹ Overview

A production-ready **Automatic License Plate Recognition (ALPR)** system that demonstrates advanced AI engineering skills through custom PyTorch implementations. This project showcases real-world deep learning expertise beyond typical high-level frameworks.

### ğŸ¯ What Makes This Special?

- **Custom Training Loop** â€” Hand-coded PyTorch training with AMP, gradient clipping, and cosine annealing
- **Advanced Algorithms** â€” SORT tracker (Kalman Filter + Hungarian), DFS/BFS graph algorithms, spatial hierarchies
- **Professional Engineering** â€” OOP design patterns (ABC, Factory, Singleton, Composition)
- **Full-Stack ML** â€” From data loading to REST API deployment
- **Portfolio-Ready** â€” Clean code, comprehensive documentation, production mindset

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ” Detection & Recognition
- **Vehicle Detection** using pretrained FasterRCNN
- **License Plate Detection** with custom-trained model
- **OCR** with EasyOCR + regex postprocessing
- **Multi-class support** ready for expansion

</td>
<td width="50%">

### ğŸ“Š Tracking & Counting
- **SORT Tracker** (Kalman Filter + Hungarian Algorithm)
- **Line-crossing counter** with cross product math
- **Re-identification** using BFS shortest path
- **Trajectory reconstruction** with DFS

</td>
</tr>
<tr>
<td width="50%">

### ğŸ§  Advanced Algorithms
- **Graph Theory:** DFS trajectory tracking, BFS re-ID
- **Linear Algebra:** IoU computation, bbox transforms
- **Probability:** Kalman Filter state estimation
- **Optimization:** Hungarian assignment algorithm

</td>
<td width="50%">

### ğŸš€ Production Features
- **FastAPI REST API** for easy integration
- **Docker support** for containerized deployment
- **Config management** with YAML + Singleton pattern
- **Dual logging** (TensorBoard + CSV)

</td>
</tr>
</table>

---

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    A[ğŸ“¹ Video Input] --> B[ğŸš— Vehicle Detector]
    B --> C[ğŸ“ SORT Tracker]
    C --> D[ğŸ”¢ Line Counter]
    B --> E[ğŸ” Plate Detector]
    E --> F[ğŸ“ OCR Engine]
    D --> G[ğŸ“Š Results]
    F --> G
    
    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fff3e0
    style F fill:#fce4ec
    style G fill:#e0f2f1
```

**Pipeline Flow:**
1. **Vehicle Detection** â†’ FasterRCNN (COCO pretrained)
2. **Tracking** â†’ SORT (Kalman Filter + Hungarian matching)
3. **Counting** â†’ Cross product line-crossing detection
4. **Plate Detection** â†’ Custom FasterRCNN-MobileNetV3
5. **OCR** â†’ EasyOCR + Vietnamese regex validation
6. **Output** â†’ JSON results via FastAPI

---

## ğŸš€ Quick Start

### ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/nguyencongtuyenlp/license-plate-recognition.git
cd license-plate-recognition

# Install dependencies
pip install -r requirements.txt
```

### ğŸ“¥ Download Dataset

**Option 1: Automatic (Recommended)**
```bash
python scripts/download_dataset.py --format coco --output data
```

**Option 2: Manual**
1. Visit [Roboflow Dataset](https://universe.roboflow.com/nguyn-cng-tuyn/my-first-project-usuhh-7gecz)
2. Download COCO format (version 2)
3. Extract to `data/coco/`

**Dataset Specs:**
- ğŸ“Š **Total:** 8,255 images
- ğŸ¯ **Classes:** 1 (license_plate)
- ğŸ“ **Split:** Train (5,756) | Val (1,640) | Test (859)
- ğŸ“ **Format:** COCO JSON

### ğŸ“ Training

```bash
# Basic training
python -m src train --config configs/train_plate_detector.yaml

# Custom settings
python -m src train \
  --config configs/train_plate_detector.yaml \
  --epochs 50 \
  --batch-size 8 \
  --device cuda
```

### ğŸ”® Inference

```bash
# Process video
python -m src infer \
  --video input.mp4 \
  --output output.mp4 \
  --device cuda

# Evaluate model
python -m src evaluate \
  --checkpoint checkpoints/best.pth \
  --config configs/train_plate_detector.yaml
```

### ğŸŒ API Server

```bash
# Start server
python -m src api --host 0.0.0.0 --port 8000

# Test endpoint
curl -X POST http://localhost:8000/infer_video \
  -F "file=@test_video.mp4"
```

**API Docs:** http://localhost:8000/docs (auto-generated Swagger UI)

---

## ğŸ§  Technical Skills Demonstrated

<table>
<thead>
<tr>
<th width="20%">Category</th>
<th width="30%">Skill</th>
<th width="30%">Implementation</th>
<th width="20%">File</th>
</tr>
</thead>
<tbody>

<tr>
<td rowspan="4"><b>ğŸ”· Deep Learning</b></td>
<td>Custom Training Loop</td>
<td>AMP, gradient clipping, warmup</td>
<td><code>training/trainer.py</code></td>
</tr>
<tr>
<td>Transfer Learning</td>
<td>FasterRCNN fine-tuning</td>
<td><code>models/plate_detector.py</code></td>
</tr>
<tr>
<td>Evaluation Metrics</td>
<td>Hand-coded mAP, IoU, PR curves</td>
<td><code>training/metrics.py</code></td>
</tr>
<tr>
<td>Data Augmentation</td>
<td>Custom transform pipeline</td>
<td><code>data/transforms.py</code></td>
</tr>

<tr>
<td rowspan="3"><b>ğŸ“Š Algorithms</b></td>
<td>Graph Traversal (DFS)</td>
<td>Trajectory reconstruction, ROI tree</td>
<td><code>tracking/track_graph.py</code></td>
</tr>
<tr>
<td>Graph Traversal (BFS)</td>
<td>Re-ID shortest path, NMS clustering</td>
<td><code>tracking/associator.py</code></td>
</tr>
<tr>
<td>Kalman Filter</td>
<td>7D state estimation for tracking</td>
<td><code>tracking/sort_tracker.py</code></td>
</tr>

<tr>
<td rowspan="4"><b>ğŸ›ï¸ Design Patterns</b></td>
<td>Abstract Base Class</td>
<td>Detector interface</td>
<td><code>models/base_detector.py</code></td>
</tr>
<tr>
<td>Factory Pattern</td>
<td>Detector creation by name</td>
<td><code>models/base_detector.py</code></td>
</tr>
<tr>
<td>Singleton Pattern</td>
<td>Config manager</td>
<td><code>utils/config.py</code></td>
</tr>
<tr>
<td>Composition</td>
<td>Pipeline architecture</td>
<td><code>inference/pipeline.py</code></td>
</tr>

<tr>
<td rowspan="2"><b>ğŸ”§ Engineering</b></td>
<td>REST API</td>
<td>FastAPI with async/await</td>
<td><code>api/app.py</code></td>
</tr>
<tr>
<td>Logging & Monitoring</td>
<td>TensorBoard + CSV dual logging</td>
<td><code>utils/logger.py</code></td>
</tr>

</tbody>
</table>

---

## ğŸ“Š Training Details

### ğŸ›ï¸ Hyperparameters

| Parameter | Value | Notes |
|-----------|-------|-------|
| **Model** | FasterRCNN-MobileNetV3-FPN | Lightweight backbone |
| **Optimizer** | SGD | momentum=0.9, weight_decay=5e-4 |
| **LR Schedule** | Cosine Annealing | 3-epoch warmup |
| **Mixed Precision** | âœ… Enabled | FP16 forward, FP32 backward |
| **Gradient Clipping** | Max norm = 10.0 | Stability |
| **Early Stopping** | Patience = 10 | Prevent overfitting |
| **Batch Size** | 4-16 | GPU dependent |
| **Epochs** | 50 (max) | Early stop ~epoch 30 |

### ğŸ’» GPU Requirements

<table>
<tr>
<th>Setup</th>
<th>GPU</th>
<th>VRAM</th>
<th>Batch Size</th>
<th>Time (50 epochs)</th>
<th>Cost</th>
</tr>

<tr>
<td>ğŸ˜ Minimum</td>
<td>GTX 1650</td>
<td>4GB</td>
<td>2-4</td>
<td>6-8 hours</td>
<td>Local</td>
</tr>

<tr>
<td>ğŸ˜Š Recommended</td>
<td>RTX 3060</td>
<td>12GB</td>
<td>8-12</td>
<td>2-3 hours</td>
<td>~$0.50/hr</td>
</tr>

<tr style="background-color: #e8f5e9;">
<td><b>âš¡ Best (FREE!)</b></td>
<td><b>T4 (Lightning.ai)</b></td>
<td><b>16GB</b></td>
<td><b>16</b></td>
<td><b>1.5-2 hours</b></td>
<td><b>FREE âœ¨</b></td>
</tr>
</table>

> **ğŸ’¡ Tip:** Use [Lightning.ai](https://lightning.ai/) free tier with T4 GPU for fastest training at zero cost!
> 
> **ğŸ“– Guide:** See [docs/lightning_ai_setup.md](docs/lightning_ai_setup.md) for step-by-step setup.

---

## ğŸ“ Project Structure

```
license-plate-recognition/
â”‚
â”œâ”€â”€ ğŸ“‚ configs/
â”‚   â””â”€â”€ train_plate_detector.yaml    # Training configuration
â”‚
â”œâ”€â”€ ğŸ“‚ data/                          # Dataset (downloaded via script)
â”‚   â””â”€â”€ coco/                         # COCO format: train/valid/test
â”‚
â”œâ”€â”€ ğŸ“‚ src/                           # Source code
â”‚   â”œâ”€â”€ data/          # Dataset + transforms
â”‚   â”œâ”€â”€ models/        # Detectors (ABC + Factory)
â”‚   â”œâ”€â”€ training/      # Training loop + metrics
â”‚   â”œâ”€â”€ tracking/      # SORT + graph algorithms
â”‚   â”œâ”€â”€ counting/      # Line-crossing counter
â”‚   â”œâ”€â”€ ocr/           # EasyOCR + postprocessing
â”‚   â”œâ”€â”€ postprocess/   # NMS + ROI tree
â”‚   â”œâ”€â”€ inference/     # End-to-end pipeline
â”‚   â”œâ”€â”€ api/           # FastAPI service
â”‚   â””â”€â”€ utils/         # Config + logging
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/
â”‚   â”œâ”€â”€ download_dataset.py           # Roboflow downloader
â”‚   â”œâ”€â”€ train_plate_detector.sh       # Training script
â”‚   â””â”€â”€ run_api.sh                    # API launcher
â”‚
â”œâ”€â”€ ğŸ“‚ docs/
â”‚   â””â”€â”€ lightning_ai_setup.md         # GPU training guide
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt               # Python dependencies
â”œâ”€â”€ ğŸ³ Dockerfile                     # Container setup
â””â”€â”€ ğŸ“– README.md                      # You are here!
```

---

## ğŸ¯ Roadmap & Future Work

- [ ] **Multi-class vehicle training** (not just pretrained COCO)
- [ ] **DeepSORT** with Re-ID network for appearance features
- [ ] **Vietnamese OCR fine-tuning** for better accuracy
- [ ] **Real-time streaming** inference with WebSocket
- [ ] **Model quantization** (INT8) for edge deployment
- [ ] **Multi-camera tracking** across different viewpoints

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Nguyen Cong Tuyen**

- ğŸŒ GitHub: [@nguyencongtuyenlp](https://github.com/nguyencongtuyenlp)
- ğŸ“§ Email: nguyencongtuyenlp@gmail.com

---

<div align="center">

### â­ If you find this project helpful, please give it a star!

**Built with â¤ï¸ using PyTorch**

</div>
